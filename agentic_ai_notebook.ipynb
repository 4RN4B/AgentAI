{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install openai google-genai","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:39.103508Z","iopub.execute_input":"2025-12-01T19:15:39.103804Z","iopub.status.idle":"2025-12-01T19:15:42.034689Z","shell.execute_reply.started":"2025-12-01T19:15:39.103786Z","shell.execute_reply":"2025-12-01T19:15:42.032506Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (2.7.1)\nRequirement already satisfied: google-genai in /usr/local/lib/python3.11/dist-packages (1.48.0)\nRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.11.0)\nRequirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\nRequirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.10.0)\nRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.12.4)\nRequirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\nRequirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\nRequirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.15.0)\nRequirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.38.0)\nRequirement already satisfied: requests<3.0.0,>=2.28.1 in /usr/local/lib/python3.11/dist-packages (from google-genai) (2.32.5)\nRequirement already satisfied: tenacity<9.2.0,>=8.2.3 in /usr/local/lib/python3.11/dist-packages (from google-genai) (9.1.2)\nRequirement already satisfied: websockets<15.1.0,>=13.0.0 in /usr/local/lib/python3.11/dist-packages (from google-genai) (15.0.1)\nRequirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.11)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (5.5.2)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (0.4.2)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-genai) (4.9.1)\nRequirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.10.5)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\nRequirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\nRequirement already satisfied: pydantic-core==2.41.5 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.41.5)\nRequirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.2)\nRequirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (3.4.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.28.1->google-genai) (2.5.0)\nRequirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-genai) (0.6.1)\n","output_type":"stream"}],"execution_count":600},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.036781Z","iopub.execute_input":"2025-12-01T19:15:42.037048Z","iopub.status.idle":"2025-12-01T19:15:42.043885Z","shell.execute_reply.started":"2025-12-01T19:15:42.037028Z","shell.execute_reply":"2025-12-01T19:15:42.042674Z"}},"outputs":[],"execution_count":601},{"cell_type":"code","source":"\"\"\"\nmulti_agent_gym_projects.py\n\nUpdated: Replaced the simulated LLM with a clear example showing how to call OpenAI's API (instructions only — code will not run here unless you provide an API key and install the OpenAI Python package).\n\nAlso: extended the WorkoutAgent to produce detailed exercises with sets/reps/load suggestions based on goal.\n\nHow to enable OpenAI in this file:\n  1. pip install openai google-genai\n  2. export OPENAI_API_KEY=\"sk-...\" (or set as env var on Windows)\n  3. Optionally change MODEL_NAME below to your preferred model (e.g., \"gpt-4o\", \"gpt-4o-mini\", or Chat Completions model).\n\nNote: This file contains a safe example of integrating with OpenAI. It's written so you can run it locally or in Kaggle after you set the env var.\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.045226Z","iopub.execute_input":"2025-12-01T19:15:42.045573Z","iopub.status.idle":"2025-12-01T19:15:42.070643Z","shell.execute_reply.started":"2025-12-01T19:15:42.045545Z","shell.execute_reply":"2025-12-01T19:15:42.069858Z"}},"outputs":[{"execution_count":602,"output_type":"execute_result","data":{"text/plain":"'\\nmulti_agent_gym_projects.py\\n\\nUpdated: Replaced the simulated LLM with a clear example showing how to call OpenAI\\'s API (instructions only — code will not run here unless you provide an API key and install the OpenAI Python package).\\n\\nAlso: extended the WorkoutAgent to produce detailed exercises with sets/reps/load suggestions based on goal.\\n\\nHow to enable OpenAI in this file:\\n  1. pip install openai google-genai\\n  2. export OPENAI_API_KEY=\"sk-...\" (or set as env var on Windows)\\n  3. Optionally change MODEL_NAME below to your preferred model (e.g., \"gpt-4o\", \"gpt-4o-mini\", or Chat Completions model).\\n\\nNote: This file contains a safe example of integrating with OpenAI. It\\'s written so you can run it locally or in Kaggle after you set the env var.\\n'"},"metadata":{}}],"execution_count":602},{"cell_type":"code","source":"from __future__ import annotations\nimport os\nimport random\nimport threading\nfrom typing import List, Dict, Any, Optional, Tuple\nimport time\nimport logging\nimport uuid\n# Optional OpenAI integration. This demonstrates how you'd replace the simulated LLM.\n# The code will not run here unless you install openai and provide an API key.\n# Install: pip install openai\n# Environment variable: OPENAI_API_KEY\nimport openai\nimport google.generativeai as genai\nfrom google import genai\nfrom kaggle_secrets import UserSecretsClient\nimport json\nimport re\nfrom typing import Tuple","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.072353Z","iopub.execute_input":"2025-12-01T19:15:42.072556Z","iopub.status.idle":"2025-12-01T19:15:42.090864Z","shell.execute_reply.started":"2025-12-01T19:15:42.072542Z","shell.execute_reply":"2025-12-01T19:15:42.089407Z"}},"outputs":[],"execution_count":603},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\nGEMINI_API_KEY = user_secrets.get_secret(\"GEMINI_API_KEY\")\nMODEL_NAME = \"gemini-2.5-flash\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.091845Z","iopub.execute_input":"2025-12-01T19:15:42.092050Z","iopub.status.idle":"2025-12-01T19:15:42.197446Z","shell.execute_reply.started":"2025-12-01T19:15:42.092034Z","shell.execute_reply":"2025-12-01T19:15:42.196618Z"}},"outputs":[],"execution_count":604},{"cell_type":"code","source":"# CONFIG\n# MODEL_NAME = \"gpt-4o-mini\"  # Change to the model you want to use\n# OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n# GEMINI_API_KEY = os.getenv(\"GEMINI_API_KEY\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.198430Z","iopub.execute_input":"2025-12-01T19:15:42.198654Z","iopub.status.idle":"2025-12-01T19:15:42.203097Z","shell.execute_reply.started":"2025-12-01T19:15:42.198637Z","shell.execute_reply":"2025-12-01T19:15:42.202181Z"}},"outputs":[],"execution_count":605},{"cell_type":"code","source":"# LLM wrapper: will call OpenAI if package & key are present, otherwise returns a deterministic fallback.\ndef call_openai_chat(prompt: str, model: str = MODEL_NAME, temperature: float = 0.6, max_tokens: int = 400) -> str:\n    \"\"\"\n    Calls the OpenAI ChatCompletions endpoint (example). This function is provided as an implementation guide.\n\n    Important: This demonstrates the request body shape for openai.ChatCompletion.create. Depending on the OpenAI SDK\n    version you use, function names and parameters might differ slightly. Consult the official OpenAI Python docs for\n    your installed SDK version.\n\n    Replace usage with whichever OpenAI client or method you prefer.\n    \"\"\"\n    if openai is None or not OPENAI_API_KEY:\n        # Fallback deterministic reply when OpenAI isn't available\n        return (\n            \"[LLM not configured] Provide an OPENAI_API_KEY and install the 'openai' package to enable real LLM calls.\\n\"\n            + \"Prompt received:\\n\" + prompt[:500]\n        )\n\n    # configure client\n    openai.api_key = OPENAI_API_KEY\n\n    # Example using ChatCompletion (classic SDK). Your environment or SDK version may use a different call.\n    try:\n        response = openai.ChatCompletion.create(\n            model=model,\n            messages=[{\"role\": \"user\", \"content\": prompt}],\n            temperature=temperature,\n            max_tokens=max_tokens,\n        )\n        # Extract assistant reply\n        if isinstance(response, dict):\n            # typical structure\n            return response[\"choices\"][0][\"message\"][\"content\"].strip()\n        else:\n            # Some SDKs return objects with attributes\n            return response.choices[0].message.content.strip()\n    except Exception as e:\n        return f\"[OpenAI call failed] {e}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.204068Z","iopub.execute_input":"2025-12-01T19:15:42.204347Z","iopub.status.idle":"2025-12-01T19:15:42.222296Z","shell.execute_reply.started":"2025-12-01T19:15:42.204299Z","shell.execute_reply":"2025-12-01T19:15:42.221485Z"}},"outputs":[],"execution_count":606},{"cell_type":"code","source":"def call_gemini(prompt: str, model: str = \"gemini-2.5-flash\", temperature: float = 0.6, max_tokens: int = 400) -> str:\n    \"\"\"\n    Call Google Gemini via the Google GenAI SDK if available and configured.\n    Falls back to raising RuntimeError if not configured (caller should catch and fallback).\n    \"\"\"\n    if genai is None:\n        raise RuntimeError(\"google-genai SDK not installed (pip install google-genai)\")\n\n    # Configure client: prefer explicit API key if provided, otherwise rely on ADC\n    try:\n        # Some examples use genai.configure(...) and others use client objects.\n        # Attempt common patterns used in Google docs.\n        if GEMINI_API_KEY:\n            # older/newer SDKs vary; configure global API key if available\n            try:\n                genai.configure(api_key=GEMINI_API_KEY)\n            except AttributeError:\n                # some SDK variants expect client instantiation\n                client = genai.Client(api_key=GEMINI_API_KEY)\n            resp = client.models.generate_content(model=model, contents=prompt)\n            # print(\"Gemini Call\", resp)\n            print(\"Gemini Call\")\n            return getattr(resp, \"text\", str(resp))\n        # If configure not used, try client interface\n        try:\n            client = genai.Client()  # will use ADC if no API key\n            resp = client.models.generate_content(model=model, contents=prompt)\n            # resp.text is the usual attribute in examples\n            return getattr(resp, \"text\", str(resp))\n        except Exception:\n            # fallback to older method using direct model object\n            model_obj = genai.GenerativeModel(model)\n            response = model_obj.generate_content(prompt)\n            return getattr(response, \"text\", str(response))\n    except Exception as e:\n        # bubble up so caller can fall back to timed_llm_call/OpenAI fallback\n        raise RuntimeError(f\"Gemini call failed: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.223177Z","iopub.execute_input":"2025-12-01T19:15:42.223394Z","iopub.status.idle":"2025-12-01T19:15:42.247669Z","shell.execute_reply.started":"2025-12-01T19:15:42.223376Z","shell.execute_reply":"2025-12-01T19:15:42.246093Z"}},"outputs":[],"execution_count":607},{"cell_type":"code","source":"logging.basicConfig(level=logging.INFO, format=\"%(asctime)s %(levelname)s %(message)s\")\nlogger = logging.getLogger(\"multi_agent_gym\")\n\nMETRICS = {\n    \"llm_calls\": 0,\n    \"errors\": 0,\n    \"total_llm_time_s\": 0.0,\n    \"sequential_flows\": 0,\n    \"parallel_flows\": 0,\n    \"loop_iterations\": 0,\n}\n\n\ndef print_metrics():\n    logger.info(\"METRICS: %s\", METRICS)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.248737Z","iopub.execute_input":"2025-12-01T19:15:42.248931Z","iopub.status.idle":"2025-12-01T19:15:42.272618Z","shell.execute_reply.started":"2025-12-01T19:15:42.248915Z","shell.execute_reply":"2025-12-01T19:15:42.271295Z"}},"outputs":[],"execution_count":608},{"cell_type":"code","source":"def timed_llm_call(prompt: str, model: str = MODEL_NAME, temperature: float = 0.6, max_tokens: int = 400) -> str:\n    start = time.time()\n    METRICS[\"llm_calls\"] += 1\n    call_id = uuid.uuid4().hex[:8]\n    logger.info(\"LLM call %s started (len(prompt)=%d)\", call_id, len(prompt))\n    try:\n        out = call_gemini(prompt, model=model, temperature=temperature, max_tokens=max_tokens)\n        # print(\"Gemini Call\", out)\n        print(\"Gemini Call\")\n        return out\n    except Exception:\n        METRICS[\"errors\"] += 1\n        logger.exception(\"LLM call %s error\", call_id)\n        raise\n    finally:\n        elapsed = time.time() - start\n        METRICS[\"total_llm_time_s\"] += elapsed\n        logger.info(\"LLM call %s finished in %.3fs\", call_id, elapsed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.276694Z","iopub.execute_input":"2025-12-01T19:15:42.277111Z","iopub.status.idle":"2025-12-01T19:15:42.302709Z","shell.execute_reply.started":"2025-12-01T19:15:42.277089Z","shell.execute_reply":"2025-12-01T19:15:42.301061Z"}},"outputs":[],"execution_count":609},{"cell_type":"code","source":"# ---------------------- Nutrition utilities ----------------------\ndef estimate_calories_for_meal(meal: Dict[str, Any]) -> float:\n    \"\"\"Basic calorie estimate by summing item estimates. In production, hook a nutrition DB.\n    meal: {\"items\": [{\"name\": str, \"qty\": float, \"unit\": str, \"kcal_per_unit\": float}, ...]}\n    \"\"\"\n    total = 0.0\n    for it in meal.get(\"items\", []):\n        kcal = float(it.get(\"kcal_per_unit\", 0.0)) * float(it.get(\"qty\", 1.0))\n        total += kcal\n    return round(total, 2)\n\n\ndef sum_micronutrients(meals: List[Dict[str, Any]]) -> Dict[str, float]:\n    totals: Dict[str, float] = {}\n    for meal in meals:\n        for micro, val in meal.get(\"micros\", {}).items():\n            totals[micro] = totals.get(micro, 0.0) + float(val)\n    return {k: round(v, 2) for k, v in totals.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.303872Z","iopub.execute_input":"2025-12-01T19:15:42.304204Z","iopub.status.idle":"2025-12-01T19:15:42.314154Z","shell.execute_reply.started":"2025-12-01T19:15:42.304179Z","shell.execute_reply":"2025-12-01T19:15:42.312870Z"}},"outputs":[],"execution_count":610},{"cell_type":"code","source":"# ---------------------- Sample utilities & main demo ----------------------\ndef incremental_meal_generator_from_user_inputs(user_meals: Dict[str, str], iteration: int) -> List[Dict[str, Any]]:\n    # Example generator: small variations each iteration\n    estimated = estimate_meals_with_llm(user_meals)\n    # Optionally modify per iteration (e.g., add a small snack growth)\n    for m in estimated:\n        if m[\"name\"].lower().startswith(\"snack\"):\n            # increase snack qty slightly each iteration\n            m[\"total_kcal\"] = round(m[\"total_kcal\"] + iteration * 20, 2)\n    return estimated","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.315336Z","iopub.execute_input":"2025-12-01T19:15:42.315622Z","iopub.status.idle":"2025-12-01T19:15:42.333019Z","shell.execute_reply.started":"2025-12-01T19:15:42.315604Z","shell.execute_reply":"2025-12-01T19:15:42.331833Z"}},"outputs":[],"execution_count":611},{"cell_type":"code","source":"def _extract_json_substring(text: str) -> Optional[str]:\n    \"\"\"Return first {...} JSON-like substring if present, else None.\"\"\"\n    m = re.search(r\"\\[.*?\\]\", text, flags=re.DOTALL)\n    if m:\n        return m.group(0)\n    # Then try object\n    m = re.search(r\"\\{.*?\\}\", text, flags=re.DOTALL)\n    if m:\n        return m.group(0)\n    return None\n    \ndef estimate_meals_with_llm(meals_desc: Dict[str, str]) -> List[Dict[str, Any]]:\n    \"\"\"\n    meals_desc: {\"Breakfast\": \"oats 1cup, banana 1\", \"Lunch\": \"...\", ...}\n    Returns list of meal dicts: [{\"name\":\"Breakfast\", \"items\":[{\"name\":\"oats\",\"qty\":1,\"unit\":\"cup\",\"kcal\":300},...], \"total_kcal\": 400}, ...]\n    Uses timed_llm_call() if available. Falls back to a simple heuristic if not.\n    \"\"\"\n    # Build a compact instruction asking for JSON only\n    prompt_lines = [\n    \"You are a nutrition assistant.\",\n    \"You MUST return ONLY a JSON array.\",\n    \"Do NOT add any text before or after the JSON.\",\n    \"Each meal must be: {\\\"name\\\":\\\"Breakfast\\\",\\\"items\\\":[{\\\"name\\\":\\\"oats\\\",\\\"qty\\\":\\\"1\\\",\\\"unit\\\":\\\"cup\\\",\\\"kcal\\\":\\\"300\\\"}],\\\"total_kcal\\\":\\\"XXX\\\"}\",\n    ]\n    for name, desc in meals_desc.items():\n        prompt_lines.append(f\"{name}: {desc}\")\n    prompt = \"\\n\".join(prompt_lines)\n\n    llm_out = None\n    llm_out = timed_llm_call(prompt, temperature=0.0, max_tokens=400)\n    if llm_out:\n        # Try to extract JSON and parse\n        json_sub = \"[\"+_extract_json_substring(llm_out)+\"]\"\n        try:\n            parsed = json.loads(json_sub)\n            # Basic validation: ensure each meal has total_kcal numeric\n            out = []\n            for m in parsed:\n                # Normalize\n                name = m.get(\"name\")\n                items = m.get(\"items\", [])\n                total = m.get(\"total_kcal\")\n                # If total missing, sum items if possible\n                if (total is None or total == \"\") and isinstance(items, list):\n                    s = 0.0\n                    for it in items:\n                        try: s += float(it.get(\"kcal\", 0))\n                        except Exception: pass\n                    total = round(s, 2)\n                out.append({\"name\": name, \"items\": items, \"total_kcal\": float(total or 0)})\n            print(\"Out\",out)\n            return out\n        except Exception as e:\n            print(\"Exception\", e)\n            pass","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.334071Z","iopub.execute_input":"2025-12-01T19:15:42.334342Z","iopub.status.idle":"2025-12-01T19:15:42.353783Z","shell.execute_reply.started":"2025-12-01T19:15:42.334318Z","shell.execute_reply":"2025-12-01T19:15:42.352898Z"}},"outputs":[],"execution_count":612},{"cell_type":"code","source":"def compact_context(messages: List[str], summarizer=timed_llm_call, max_len_chars: int = 2000) -> str:\n    joined = \"\\n\".join(messages)\n    if len(joined) <= max_len_chars:\n        return joined\n\n    prompt = (\n        \"You are a context compaction assistant. Summarize the following \"\n        \"conversation/messages into a concise 3-bullet summary:\\n\\n\"\n        + joined[:10000]\n    )\n    try:\n        summary = summarizer(prompt, temperature=0.2, max_tokens=300)\n        compacted = \"[COMPACT_SUMMARY]\\n\" + summary.strip()\n        logger.info(\"Context compacted from %d chars to %d chars\", len(joined), len(compacted))\n        return compacted\n    except Exception:\n        logger.exception(\"Context compaction failed; returning truncated original\")\n        return joined[-max_len_chars:]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.354631Z","iopub.execute_input":"2025-12-01T19:15:42.354867Z","iopub.status.idle":"2025-12-01T19:15:42.380489Z","shell.execute_reply.started":"2025-12-01T19:15:42.354849Z","shell.execute_reply":"2025-12-01T19:15:42.379320Z"}},"outputs":[],"execution_count":613},{"cell_type":"code","source":"# ---------------------- Agents ----------------------\nclass BaseAgent:\n    def run(self, *args, **kwargs):\n        raise NotImplementedError","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.381579Z","iopub.execute_input":"2025-12-01T19:15:42.381831Z","iopub.status.idle":"2025-12-01T19:15:42.398113Z","shell.execute_reply.started":"2025-12-01T19:15:42.381815Z","shell.execute_reply":"2025-12-01T19:15:42.396946Z"}},"outputs":[],"execution_count":614},{"cell_type":"code","source":"class FoodAgent(BaseAgent):\n    def analyze_meals(self, meals: List[Dict[str, Any]]) -> Dict[str, Any]:\n        total_calories = sum(estimate_calories_for_meal(m) for m in meals)\n        micros = sum_micronutrients(meals)\n\n        messages = [\n            \"Nutrition assistant context:\",\n            f\"Meals data: {meals}\",\n            f\"Micronutrients summary: {micros}\",\n            f\"Total calories (est): {total_calories}\",\n            \"Task: Provide a short natural-language summary and 3 practical tips.\"\n        ]\n\n        compact_prompt = compact_context(messages)\n        llm_reply = timed_llm_call(compact_prompt)\n        return {\n            \"total_calories\": total_calories,\n            \"micronutrients\": micros,\n            \"llm_summary\": llm_reply,\n        }\n\n    def run(self, meals: List[Dict[str, Any]]):\n        return self.analyze_meals(meals)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.399487Z","iopub.execute_input":"2025-12-01T19:15:42.400015Z","iopub.status.idle":"2025-12-01T19:15:42.416807Z","shell.execute_reply.started":"2025-12-01T19:15:42.399984Z","shell.execute_reply":"2025-12-01T19:15:42.415924Z"}},"outputs":[],"execution_count":615},{"cell_type":"code","source":"# Extended WorkoutAgent: returns exercises with reps/sets/load suggestions.\nclass WorkoutAgent(BaseAgent):\n    # A small library of exercises mapped to muscle groups and equipment\n    EXERCISE_DB = {\n        \"push\": [\n            {\"name\": \"Barbell Bench Press\", \"equipment\": \"barbell\", \"primary\": \"chest\"},\n            {\"name\": \"Dumbbell Shoulder Press\", \"equipment\": \"dumbbells\", \"primary\": \"shoulders\"},\n            {\"name\": \"Push-up\", \"equipment\": \"bodyweight\", \"primary\": \"chest\"},\n        ],\n        \"pull\": [\n            {\"name\": \"Barbell Row\", \"equipment\": \"barbell\", \"primary\": \"back\"},\n            {\"name\": \"Pull-up\", \"equipment\": \"bodyweight\", \"primary\": \"back\"},\n            {\"name\": \"Dumbbell Curl\", \"equipment\": \"dumbbells\", \"primary\": \"biceps\"},\n        ],\n        \"legs\": [\n            {\"name\": \"Back Squat\", \"equipment\": \"barbell\", \"primary\": \"quads\"},\n            {\"name\": \"Romanian Deadlift\", \"equipment\": \"barbell\", \"primary\": \"hamstrings\"},\n            {\"name\": \"Lunges\", \"equipment\": \"bodyweight\", \"primary\": \"quads\"},\n        ],\n        \"core\": [\n            {\"name\": \"Plank\", \"equipment\": \"bodyweight\", \"primary\": \"core\"},\n            {\"name\": \"Hanging Leg Raise\", \"equipment\": \"bodyweight\", \"primary\": \"core\"},\n        ],\n    }\n\n    # Simple heuristics for reps/sets/load by training goal\n    GOAL_PARAMS = {\n        \"strength\": {\"sets\": [3, 5], \"reps\": [3, 6], \"intensity_pct\": [80, 90]},  # % of 1RM\n        \"hypertrophy\": {\"sets\": [3, 4], \"reps\": [6, 12], \"intensity_pct\": [65, 80]},\n        \"endurance\": {\"sets\": [2, 3], \"reps\": [12, 20], \"intensity_pct\": [40, 65]},\n        \"general\": {\"sets\": [3, 4], \"reps\": [8, 12], \"intensity_pct\": [60, 75]},\n    }\n\n    def suggest_load(self, user_profile: Dict[str, Any], intensity_pct: float, exercise_name: str) -> Optional[float]:\n        \"\"\"\n        Suggest a simple absolute load (kg) for barbell/dumbbell lifts using an optional 1RM estimate in user_profile.\n        If no 1RM is provided, return None to indicate 'RPE-style' guidance.\n        \"\"\"\n        one_rm_map = user_profile.get(\"1rm\", {})  # e.g., {\"Barbell Bench Press\": 100}\n        if exercise_name in one_rm_map:\n            one_rm = float(one_rm_map[exercise_name])\n            return round(one_rm * (intensity_pct / 100.0), 1)\n        return None\n\n    def pick_exercises_for_day(self, focus: str, num_exercises: int = 4) -> List[Dict[str, Any]]:\n        pool = []\n        # Build pool from focus and some auxiliary groups\n        if focus == \"full_body\":\n            pool = self.EXERCISE_DB[\"push\"] + self.EXERCISE_DB[\"pull\"] + self.EXERCISE_DB[\"legs\"] + self.EXERCISE_DB[\"core\"]\n        else:\n            pool = self.EXERCISE_DB.get(focus, []) + self.EXERCISE_DB.get(\"core\", [])\n\n        chosen = random.sample(pool, min(len(pool), num_exercises))\n        return chosen\n\n    def create_exercise_detail(self, exercise: Dict[str, Any], goal: str, user_profile: Dict[str, Any]) -> Dict[str, Any]:\n        params = self.GOAL_PARAMS.get(goal, self.GOAL_PARAMS[\"general\"])\n        sets = random.randint(params[\"sets\"][0], params[\"sets\"][1])\n        reps = random.randint(params[\"reps\"][0], params[\"reps\"][1])\n        intensity_pct = random.uniform(params[\"intensity_pct\"][0], params[\"intensity_pct\"][1])\n        load = self.suggest_load(user_profile, intensity_pct, exercise[\"name\"]) if exercise[\"equipment\"] in (\"barbell\", \"dumbbells\") else None\n\n        guidance = []\n        if load:\n            guidance.append(f\"Target load ~ {load} kg ({int(round(intensity_pct))}% 1RM)\")\n        else:\n            guidance.append(f\"Target intensity: ~{int(round(intensity_pct))}% effort; choose a weight that allows you to hit {reps} reps with good form.\")\n\n        # Simple progression suggestion\n        guidance.append(\"Progression: add 2.5-5% load when you hit the top of the rep range for 2 consecutive sessions.\")\n\n        return {\n            \"name\": exercise[\"name\"],\n            \"primary\": exercise.get(\"primary\"),\n            \"equipment\": exercise.get(\"equipment\"),\n            \"sets\": sets,\n            \"reps\": reps,\n            \"recommended_load_kg\": load,\n            \"notes\": guidance,\n        }\n\n    def create_5_day_plan(self, goal: str = \"general\", user_profile: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:\n        if user_profile is None:\n            user_profile = {}\n\n        # Simple 5-day split depending on goal\n        if goal == \"strength\":\n            split = [\"push\", \"pull\", \"legs\", \"push\", \"pull\"]\n        elif goal == \"hypertrophy\":\n            split = [\"push\", \"pull\", \"legs\", \"full_body\", \"legs\"]\n        else:  # general or endurance\n            split = [\"push\", \"pull\", \"legs\", \"core\", \"full_body\"]\n\n        week_plan = {}\n        for i, day_focus in enumerate(split, start=1):\n            exercises = self.pick_exercises_for_day(day_focus, num_exercises=4)\n            detailed = [self.create_exercise_detail(ex, goal, user_profile) for ex in exercises]\n            week_plan[f\"Day {i} - {day_focus}\"] = detailed\n\n        # Optionally ask LLM for a high-level program summary\n        messages = [\n            f\"User goal: {goal}\",\n            f\"User profile: {user_profile}\",\n            \"Program plan (detailed):\",\n            str(week_plan),\n            \"Task: Create a concise 3-bullet summary for this 5-day program.\"\n        ]\n        compact_prompt = compact_context(messages)\n        llm_summary = None\n        # print(genai)\n        try:\n            if genai is not None and (GEMINI_API_KEY or os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")):\n                # prime metrics/logging if you want (we reuse existing logger/METRICS)\n                logger.info(\"Attempting Gemini call for WorkoutAgent summary\")\n                llm_summary = call_gemini(compact_prompt, model=\"gemini-2.5-flash\", temperature=0.2, max_tokens=300)\n                logger.info(\"Gemini summary received (len=%d)\", len(llm_summary or \"\"))\n        except Exception as e:\n            logger.warning(\"Gemini call failed or not configured: %s\", e)\n        \n        # If Gemini not configured or call failed, use timed_llm_call() (OpenAI or fallback)\n        if not llm_summary:\n            logger.info(\"Falling back to timed_llm_call for WorkoutAgent summary\")\n            llm_summary = timed_llm_call(compact_prompt)\n        \n        return {\"plan\": week_plan, \"summary\": llm_summary}\n\n    def run(self, goal: str = \"general\", user_profile: Optional[Dict[str, Any]] = None):\n        return self.create_5_day_plan(goal, user_profile)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.417986Z","iopub.execute_input":"2025-12-01T19:15:42.418271Z","iopub.status.idle":"2025-12-01T19:15:42.447082Z","shell.execute_reply.started":"2025-12-01T19:15:42.418245Z","shell.execute_reply":"2025-12-01T19:15:42.445922Z"}},"outputs":[],"execution_count":616},{"cell_type":"code","source":"### ReminderAgent - simple agent for reminders (drink water, stretch, etc.)\nclass ReminderAgent(BaseAgent):\n    def remind_water(self, user_profile: Dict[str, Any]) -> Dict[str, Any]:\n        # Very simple decision: frequency based on goal or basic rule\n        goal = user_profile.get(\"goal\", \"general\")\n        if goal == \"endurance\":\n            freq = \"every 30-45 minutes\"\n        elif goal == \"strength\":\n            freq = \"every 45-60 minutes\"\n        else:\n            freq = \"every 60-90 minutes\"\n        msg = f\"Hydration reminder: Aim to drink water {freq} while training and throughout the day.\"\n        return {\"reminder\": msg, \"recommended_frequency\": freq}\n\n    def remind_stretch(self) -> Dict[str, Any]:\n        msg = \"Take a 3–5 minute mobility/stretch break between heavy sets or every hour during the day.\"\n        return {\"reminder\": msg}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.448182Z","iopub.execute_input":"2025-12-01T19:15:42.448523Z","iopub.status.idle":"2025-12-01T19:15:42.475114Z","shell.execute_reply.started":"2025-12-01T19:15:42.448497Z","shell.execute_reply":"2025-12-01T19:15:42.473681Z"}},"outputs":[],"execution_count":617},{"cell_type":"code","source":"class EvaluationAgent(BaseAgent):\n    def evaluate_calorie_plan(self, calories: float, target_range: Tuple[float, float]) -> Dict[str, Any]:\n        low, high = target_range\n        score = 100 - max(0, abs((calories - (low + high) / 2))) / ((high - low) / 2 + 1) * 50\n        verdict = \"within target\" if low <= calories <= high else \"outside target\"\n        return {\"score\": round(score, 1), \"verdict\": verdict}\n\n    def evaluate_workout(self, plan: Dict[str, Any]) -> Dict[str, Any]:\n        # Basic heuristics: count exercise variety and average sets/reps\n        all_ex = []\n        for day, exs in plan.items():\n            all_ex.extend(exs)\n        variety = len({e[\"name\"] for e in all_ex})\n        avg_sets = sum(e[\"sets\"] for e in all_ex) / max(1, len(all_ex))\n        return {\"variety\": variety, \"avg_sets\": round(avg_sets, 1)}\n\n    def run(self, items: Dict[str, Any]):\n        # Example combined evaluation\n        cal_eval = self.evaluate_calorie_plan(items.get(\"calories\", 0), items.get(\"target_range\", (1800, 2400)))\n        workout_eval = self.evaluate_workout(items.get(\"workout_plan\", {}))\n        return {\"cal_eval\": cal_eval, \"workout_eval\": workout_eval}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.476461Z","iopub.execute_input":"2025-12-01T19:15:42.476821Z","iopub.status.idle":"2025-12-01T19:15:42.502385Z","shell.execute_reply.started":"2025-12-01T19:15:42.476800Z","shell.execute_reply":"2025-12-01T19:15:42.501297Z"}},"outputs":[],"execution_count":618},{"cell_type":"code","source":"### MealAgent - create a meal/recipe via LLM\nclass MealAgent(BaseAgent):\n    \"\"\"\n    Create a single meal (items + qty + kcal estimates) from a natural-language description.\n    Returns: {\"name\": \"<MealName>\", \"items\": [{\"name\":..., \"qty\":..., \"unit\":..., \"kcal\":...}, ...], \"total_kcal\": ...}\n    \"\"\"\n    def create_diet_chart(self, instruction: str, user_profile: Dict[str, Any], meal_name: Optional[str] = None) -> Dict[str, Any]:\n        # Build a strong instruction asking for JSON-only output\n        prompt = (\n            \"You are a nutrition assistant. Prepare diet chart based on the user profile. \"\n            \"RETURN ONLY valid JSON (no commentary). The JSON must be a single object like:\\n\"\n            \"{\\n\"\n            f'  \"user profile\": \"{user_profile}\",\\n'\n            '  \"items\": [{\"name\":\"oats\",\"qty\":1,\"unit\":\"cup\",\"kcal\":300}, ...],\\n'\n            '  \"total_kcal\": 600\\n'\n            \"}\\n\\n\"\n            \"User instruction: \" + instruction + \"\\n\"\n        )\n\n        try:\n            llm_out = timed_llm_call(prompt, temperature=0.2, max_tokens=300)\n        except Exception as e:\n            return {\"name\": meal_name, \"items\": [], \"total_kcal\": 0, \"note\": f\"[LLM error] {e}\"}\n\n        try:\n            # Prefer parse_loose_json_list if available (returns list of objects)\n            if \"parse_loose_json_list\" in globals():\n                parsed_objs = parse_loose_json_list(llm_out)\n                # prefer first object if list returned\n                obj = parsed_objs[0] if parsed_objs else {}\n            else:\n                # fallback: try to extract JSON substring and load\n                json_sub = _extract_json_substring(llm_out)\n                if not json_sub:\n                    raise ValueError(\"No JSON found in LLM output\")\n                obj = json.loads(json_sub)\n        except Exception:\n            # If parsing fails, return raw text for debugging\n            return {\"name\": meal_name, \"items\": [], \"total_kcal\": 0, \"raw\": llm_out, \"parse_error\": True}\n\n        # Normalise fields\n        try:\n            name = obj.get(\"name\", meal_name)\n            items = obj.get(\"items\", [])\n            total = obj.get(\"total_kcal\", None)\n            if total is None:\n                # compute from item kcal if present\n                s = 0.0\n                for it in items:\n                    try: s += float(it.get(\"kcal\", 0))\n                    except Exception: pass\n                total = round(s, 2)\n            return {\"name\": name, \"items\": items, \"total_kcal\": float(total)}\n        except Exception:\n            return {\"name\": meal_name, \"items\": [], \"total_kcal\": 0, \"raw_obj\": obj}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.503411Z","iopub.execute_input":"2025-12-01T19:15:42.503676Z","iopub.status.idle":"2025-12-01T19:15:42.527785Z","shell.execute_reply.started":"2025-12-01T19:15:42.503656Z","shell.execute_reply":"2025-12-01T19:15:42.526539Z"}},"outputs":[],"execution_count":619},{"cell_type":"code","source":"### decide_tools_from_prompt - asks the LLM which tools to run given a user prompt.\ndef decide_tools_from_prompt(prompt: str) -> List[str]:\n    \"\"\"\n    Ask the LLM to map a user prompt to a small list of tool keys.\n    Returns a list like ['nutrition', 'workout', 'reminder_water'].\n    Uses timed_llm_call(); falls back to a keyword heuristic if LLM not configured.\n    \"\"\"\n    # small instruction prompt enumerating available tools\n    tools=[\"nutrition\", \"workout\", \"evaluate\", \"reminder_water\", \"reminder_stretch\", \"sequential\", \"parallel\", \"loop\", \"create_diet_chart\"]\n    instruction = (\n        \"You are an assistant that maps a user request to a list of tool names. \"\n        f\"Available tool names: {tools}\\n\\n\"\n        f\"User request: {prompt}\\n\\n\"\n        \"Return ONLY a tool name (no other text).\"\n    )\n    try:\n        resp = timed_llm_call(instruction, temperature=0.0, max_tokens=80)\n        # split on commas and return allowed tools only\n        candidates = [s.strip().lower() for s in resp.replace(\"\\n\", \",\").split(\",\") if s.strip()]\n        allowed = {\"nutrition\", \"workout\", \"evaluate\", \"reminder_water\", \"reminder_stretch\", \"sequential\", \"parallel\", \"loop\", \"create_diet_chart\"}\n        tools = [c for c in candidates if c in allowed]\n        if tools:\n            logger.info(\"LLM decided tools: %s\", tools)\n            return tools\n    except Exception as e:\n        logger.warning(\"Tool decision LLM failed: %s\", e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.528379Z","iopub.execute_input":"2025-12-01T19:15:42.528537Z","iopub.status.idle":"2025-12-01T19:15:42.553256Z","shell.execute_reply.started":"2025-12-01T19:15:42.528522Z","shell.execute_reply":"2025-12-01T19:15:42.551754Z"}},"outputs":[],"execution_count":620},{"cell_type":"code","source":"# ---------------------- Orchestrator ----------------------\nclass Orchestrator:\n    def __init__(self):\n        self.food_agent = FoodAgent()\n        self.workout_agent = WorkoutAgent()\n        self.eval_agent = EvaluationAgent()\n        self.reminder_agent = ReminderAgent()\n        self.meal_agent = MealAgent() \n\n    def sequential_flow(self, meals: List[Dict[str, Any]], user_profile: Dict[str, Any]):\n        \"\"\"\n        Sequential flow: Nutrition -> Workout Plan -> Evaluation\n        (keeps the original pipeline behavior)\n        \"\"\"\n        METRICS[\"sequential_flows\"] += 1\n        food_res = self.food_agent.run(meals)\n        workout_res = self.workout_agent.run(user_profile.get(\"goal\", \"general\"), user_profile)\n        evaluation = self.eval_agent.run({\n            \"calories\": food_res[\"total_calories\"],\n            \"workout_plan\": workout_res[\"plan\"],\n            \"target_range\": user_profile.get(\"calorie_target\", (1800, 2400))\n        })\n        return {\"food\": food_res, \"workout\": workout_res, \"evaluation\": evaluation}\n\n    def parallel_flow(self, meals: List[Dict[str, Any]], user_profile: Dict[str, Any]):\n        \"\"\"\n        Parallel flow example: Run nutrition analysis and hydration reminder concurrently,\n        but give the workout plan afterwards. Demonstrates different capabilities run in parallel.\n        \"\"\"\n        METRICS[\"parallel_flows\"] += 1\n        food_res = {}\n        reminder_res = {}\n        workout_res = {}\n\n        def run_food():\n            nonlocal food_res\n            food_res = self.food_agent.run(meals)\n\n        def run_reminder():\n            nonlocal reminder_res\n            reminder_res = self.reminder_agent.remind_water(user_profile)\n\n        # run food analysis and reminder concurrently (two different agent types)\n        t1 = threading.Thread(target=run_food)\n        t2 = threading.Thread(target=run_reminder)\n        t1.start(); t2.start(); t1.join(); t2.join()\n\n        # after parallel tasks finish, produce a workout plan (separate agent)\n        workout_res = self.workout_agent.run(user_profile.get(\"goal\", \"general\"), user_profile)\n\n        evaluation = self.eval_agent.run({\n            \"calories\": food_res.get(\"total_calories\", 0),\n            \"workout_plan\": workout_res[\"plan\"],\n            \"target_range\": user_profile.get(\"calorie_target\", (1800, 2400))\n        })\n        return {\"food\": food_res, \"reminder\": reminder_res, \"workout\": workout_res, \"evaluation\": evaluation}\n\n    def loop_agent(self, meal_generator, user_profile: Dict[str, Any], iterations: int = 3):\n        \"\"\"\n        Loop agent example that iteratively refines the user's plan.\n        On each iteration it:\n         - evaluates current plan,\n         - optionally tweaks user_profile (simple heuristic),\n         - and requests a new plan.\n        \"\"\"\n        history = []\n        for i in range(iterations):\n            METRICS[\"loop_iterations\"] += 1\n            meals = meal_generator(i)\n            res = self.sequential_flow(meals, user_profile)\n            # Simple self-improvement heuristic:\n            # if evaluation indicates calories are outside target, nudge the calorie target\n            cal_eval = res[\"evaluation\"][\"cal_eval\"]\n            low, high = user_profile.get(\"calorie_target\", (1800, 2400))\n            if cal_eval[\"verdict\"] == \"outside target\":\n                # nudge midpoint towards observed calories\n                observed = res[\"food\"][\"total_calories\"]\n                midpoint = (low + high) / 2\n                shift = (observed - midpoint) * 0.3\n                new_low, new_high = int(low + shift), int(high + shift)\n                user_profile[\"calorie_target\"] = (max(1200, new_low), max(new_low + 200, new_high))\n                logger.info(\"Loop agent adjusted calorie_target to %s\", user_profile[\"calorie_target\"])\n            history.append(res)\n        return history\n\n    def run_tools(self, tools: List[str], meals: List[Dict[str, Any]], user_profile: Dict[str, Any]):\n        \"\"\"\n        Dispatcher: run a list of tool names and return aggregated results.\n        Supported tool names: 'nutrition', 'workout', 'evaluate', 'reminder_water', 'reminder_stretch', 'sequential', 'parallel', 'loop'\n        \"\"\"\n        results = {}\n        for t in tools:\n            if t == \"nutrition\":\n                results[\"nutrition\"] = self.food_agent.run(meals)\n            elif t == \"workout\":\n                results[\"workout\"] = self.workout_agent.run(user_profile.get(\"goal\", \"general\"), user_profile)\n            elif t == \"evaluate\":\n                # requires prior nutrition and workout results; attempt to compute if missing\n                calib = results.get(\"nutrition\", {}).get(\"total_calories\", 0)\n                plan = results.get(\"workout\", {}).get(\"plan\", {})\n                results[\"evaluation\"] = self.eval_agent.run({\"calories\": calib, \"workout_plan\": plan, \"target_range\": user_profile.get(\"calorie_target\", (1800, 2400))})\n            elif t == \"reminder_water\":\n                results[\"reminder_water\"] = self.reminder_agent.remind_water(user_profile)\n            elif t == \"reminder_stretch\":\n                results[\"reminder_stretch\"] = self.reminder_agent.remind_stretch()\n            elif t == \"sequential\":\n                results[\"sequential\"] = self.sequential_flow(meals, user_profile)\n            elif t == \"parallel\":\n                results[\"parallel\"] = self.parallel_flow(meals, user_profile)\n            elif t == \"loop\":\n                results[\"loop\"] = self.loop_agent(lambda i: meals, user_profile, iterations=2)\n            elif t == \"create_diet_chart\":\n                instruction = \"Create a balanced meal suitable for the user's goal.\"\n                meal_obj = self.meal_agent.create_diet_chart(instruction, user_profile)\n                results.setdefault(\"created_meals\", []).append(meal_obj)\n            else:\n                results[t] = {\"error\": f\"Unknown tool '{t}'\"}\n        return results\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.554458Z","iopub.execute_input":"2025-12-01T19:15:42.554826Z","iopub.status.idle":"2025-12-01T19:15:42.583574Z","shell.execute_reply.started":"2025-12-01T19:15:42.554805Z","shell.execute_reply":"2025-12-01T19:15:42.582892Z"}},"outputs":[],"execution_count":621},{"cell_type":"code","source":"### LLM-guided natural-language -> user_profile extractor\ndef _extract_json_substring(text: str) -> str:\n    \"\"\"Return first {...} JSON-like substring if present, else full text.\"\"\"\n    m = re.search(r\"\\{.*\\}\", text, flags=re.DOTALL)\n    return m.group(0) if m else text\n\ndef load_user_profile_from_prompt(nl_text: str, prefer_llm: bool = True, llm_timeout: int = 10) -> dict:\n    \"\"\"\n    Convert a natural-language description of the user into a structured user_profile:\n      {\n        \"goal\": \"hypertrophy\" | \"strength\" | \"endurance\" | \"general\",\n        \"calorie_target\": (low_float, high_float),\n        \"1rm\": {\"Exercise Name\": float, ...}\n      }\n\n    Behavior:\n      - If timed_llm_call() is available it will be used (preferred).\n      - If LLM fails or is not available, a regex-based heuristic extractor runs as fallback.\n      - The function is robust to the LLM returning plaintext or a JSON object — it attempts to parse JSON out of the reply.\n    \"\"\"\n\n    # 1) Build an instruction prompt that asks for JSON only\n    instruction = (\n        \"Extract a structured user profile from this user description.\\n\\n\"\n        \"Output MUST be valid JSON only (no extra commentary). Schema:\\n\"\n        '{\\n'\n        '  \"goal\": \"<strength|hypertrophy|endurance|general>\",\\n'\n        '  \"calorie_target\": [low_number, high_number],\\n'\n        '  \"1rm\": {\"Exercise Name\": weight_number, ...}\\n'\n        '}\\n\\n'\n        \"If a value is unknown, use null for numbers or an empty object for 1rm. \"\n        \"If a value is unknown for calorie_target, assign a value according to user needs. \"\n        \"Normalize the goal to one of: strength, hypertrophy, endurance, general.\\n\\n\"\n        f\"User description:\\n\\\"\\\"\\\"\\n{nl_text}\\n\\\"\\\"\\\"\\n\"\n        \"Return only the JSON object.\"\n    )\n\n    # 2) Try to call the LLM \n    llm_response = None\n    try:\n        print(\"Gemini Call from load_user_profile_from_prompt\")\n        llm_response = timed_llm_call(instruction, temperature=0.0, max_tokens=300)\n    except Exception:\n        llm_response = None\n\n    # 3) If we got an LLM response, try to parse JSON substring\n    if llm_response:\n        try:\n            candidate = _extract_json_substring(llm_response)\n            parsed = json.loads(candidate)\n            # Basic normalization / validation:\n            # normalize goal\n            if \"goal\" in parsed:\n                g = parsed[\"goal\"].strip().lower()\n                if g.startswith(\"str\"):\n                    parsed[\"goal\"] = \"strength\"\n                elif \"hyper\" in g:\n                    parsed[\"goal\"] = \"hypertrophy\"\n                elif \"endur\" in g:\n                    parsed[\"goal\"] = \"endurance\"\n                else:\n                    parsed[\"goal\"] = \"general\"\n            else:\n                parsed.setdefault(\"goal\", \"general\")\n\n            # calorie_target -> tuple\n            if \"calorie_target\" in parsed:\n                low = float(parsed[\"calorie_target\"][0]) if parsed[\"calorie_target\"][0] is not None else None\n                high = float(parsed[\"calorie_target\"][1]) if parsed[\"calorie_target\"][1] is not None else None\n                parsed[\"calorie_target\"] = (low, high)\n            else:\n                parsed.setdefault(\"calorie_target\", (None, None))\n\n            # 1rm: ensure dict of floats\n            if \"1rm\" in parsed and isinstance(parsed[\"1rm\"], dict):\n                parsed[\"1rm\"] = {k.strip(): float(v) for k, v in parsed[\"1rm\"].items()}\n            else:\n                parsed[\"1rm\"] = {}\n\n            return parsed\n        except Exception:\n            # fall through to heuristic fallback\n            llm_response = llm_response  # for debugging if needed\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.584272Z","iopub.execute_input":"2025-12-01T19:15:42.584479Z","iopub.status.idle":"2025-12-01T19:15:42.609044Z","shell.execute_reply.started":"2025-12-01T19:15:42.584464Z","shell.execute_reply":"2025-12-01T19:15:42.608192Z"}},"outputs":[],"execution_count":622},{"cell_type":"code","source":"### main now accepts a user prompt; LLM decides which tools to call\ndef main():\n    orchestrator = Orchestrator()\n\n    # 1) Get user profile basics or interactive creation\n    use_defaults = input(\"Define user profile like goals, calorie count, Max repition or press d for default profile: \").strip().lower()\n    if use_defaults == \"d\":\n        # default placeholder (will be overwritten below by height/weight/calories)\n        user_profile = {\n            \"goal\": \"hypertrophy\",\n            \"calorie_target\": (2500, 3000),\n            \"1rm\": {}\n        }\n    else:\n        # If you have an interactive loader, call it; else start with minimal profile\n        try:\n            user_profile = load_user_profile_from_prompt()\n        except Exception:\n            user_profile = {\"goal\": \"general\", \"calorie_target\": (None, None), \"1rm\": {}}\n\n    print(\"\\nNow tell me what you *usually* eat in each meal (brief descriptions).\")\n    breakfast_desc = input(\"Breakfast (e.g., 'oats 1 cup, banana 1'): \").strip()\n    lunch_desc = input(\"Lunch (e.g., 'rice 200g, chicken 150g'): \").strip()\n    snacks_desc = input(\"Snacks (e.g., 'almonds 30g'): \").strip()\n    dinner_desc = input(\"Dinner (e.g., 'salmon 150g, salad'): \").strip()\n\n    # 2) Get height & weight\n    def _read_float(prompt):\n        while True:\n            v = input(prompt).strip()\n            try:\n                return float(v)\n            except Exception:\n                print(\"Please enter a numeric value.\")\n    weight_kg = _read_float(\"Enter your weight in kg (e.g., 75): \")\n    height_cm = _read_float(\"Enter your height in cm (e.g., 175): \")\n    # store in profile\n    user_profile[\"weight_kg\"] = weight_kg\n    user_profile[\"height_cm\"] = height_cm\n\n    # 3) Build meal descriptions dict and ask LLM to compute calories\n    user_meals = {\n        \"Breakfast\": breakfast_desc or \"\",\n        \"Lunch\": lunch_desc or \"\",\n        \"Snacks\": snacks_desc or \"\",\n        \"Dinner\": dinner_desc or \"\"\n    }\n\n    print(\"\\nEstimating calories for your meals (LLM will calculate item calories)...\")\n    meal_list = estimate_meals_with_llm(user_meals)\n    print(\"meal_list\",meal_list)\n    # attach computed meals to profile (and also provide as meals for orchestrator)\n    total_calories = sum(m.get(\"total_kcal\", 0) for m in meal_list)\n    user_profile[\"computed_meals\"] = meal_list\n\n    # 4) Compute a calorie_target from height & weight using Mifflin-St Jeor approximation (ASSUMPTIONS)\n    # NOTE: we assume default age=30 and male sex to compute BMR. If you want sex/age, prompt for them earlier.\n    age = 30\n    male = True  # default assumption; for female subtract 161 instead of add 5\n    if male:\n        bmr = 10 * weight_kg + 6.25 * height_cm - 5 * age + 5\n    else:\n        bmr = 10 * weight_kg + 6.25 * height_cm - 5 * age - 161\n    # apply a light activity factor (sedentary to moderate). You can ask user for activity later.\n    activity_factor = 1.4\n    maintenance = round(bmr * activity_factor)\n    # set a target range +/- 300 kcal as a simple default\n    user_profile[\"calorie_target\"] = (max(1200, maintenance - 300), maintenance + 300)\n\n    print(f\"Estimated daily calories from typical meals: {total_calories} kcal\")\n    print(f\"Computed maintenance estimate (assumed age=30, activity factor={activity_factor}): {maintenance} kcal\")\n    print(f\"User calorie target set to: {user_profile['calorie_target']}\")\n\n    # 5) Prepare meals in the format agents expect (list of dicts)\n    meals_for_agents = meal_list  # already list of {\"name\",\"items\",\"total_kcal\"}\n\n    # 6) Ask the user what they want the assistant to do\n    user_prompt = input(\"\\nWhat would you like me to do now? (e.g., 'Make me a workout plan and remind me to drink water', or 'evaluate my meals', or 'diet chart'): \").strip()\n    if not user_prompt:\n        print(\"No prompt provided — running sequential demo.\")\n        tools = [\"sequential\"]\n    else:\n        tools = decide_tools_from_prompt(user_prompt)\n\n    # 7) Run selected tools\n    results = orchestrator.run_tools(tools, meals_for_agents, user_profile)\n\n    # 8) Present results and metrics\n    import json\n    print(\"=== Results ===\")\n    print(json.dumps(results, indent=2, default=str))\n    print_metrics()\n\nif __name__ == \"__main__\":\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-12-01T19:15:42.610074Z","iopub.execute_input":"2025-12-01T19:15:42.610247Z","iopub.status.idle":"2025-12-01T19:18:17.189469Z","shell.execute_reply.started":"2025-12-01T19:15:42.610233Z","shell.execute_reply":"2025-12-01T19:18:17.188587Z"}},"outputs":[{"output_type":"stream","name":"stdin","text":"Define user profile like goals, calorie count, Max repition or press d for default profile:  Strength\n"},{"name":"stdout","text":"\nNow tell me what you *usually* eat in each meal (brief descriptions).\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"Breakfast (e.g., 'oats 1 cup, banana 1'):  oats 1 cup, banana 1\nLunch (e.g., 'rice 200g, chicken 150g'):  rice 200g, chicken 150g\nSnacks (e.g., 'almonds 30g'):  almonds 30g\nDinner (e.g., 'salmon 150g, salad'):  salmon 150g, salad\nEnter your weight in kg (e.g., 75):  65\nEnter your height in cm (e.g., 175):  150\n"},{"name":"stderr","text":"2025-12-01 19:17:28,860 INFO LLM call a8c0110a started (len(prompt)=342)\n2025-12-01 19:17:28,948 INFO AFC is enabled with max remote calls: 10.\n","output_type":"stream"},{"name":"stdout","text":"\nEstimating calories for your meals (LLM will calculate item calories)...\n","output_type":"stream"},{"name":"stderr","text":"2025-12-01 19:17:38,354 INFO HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 19:17:38,357 INFO LLM call a8c0110a finished in 9.497s\n","output_type":"stream"},{"name":"stdout","text":"Gemini Call\nGemini Call\nOut [{'name': 'Breakfast', 'items': [{'name': 'oats', 'qty': '1', 'unit': 'cup', 'kcal': '300'}, {'name': 'banana', 'qty': '1', 'unit': 'item', 'kcal': '100'}], 'total_kcal': 400.0}, {'name': 'Lunch', 'items': [{'name': 'rice', 'qty': '200', 'unit': 'g', 'kcal': '260'}, {'name': 'chicken', 'qty': '150', 'unit': 'g', 'kcal': '250'}], 'total_kcal': 510.0}, {'name': 'Snacks', 'items': [{'name': 'almonds', 'qty': '30', 'unit': 'g', 'kcal': '170'}], 'total_kcal': 170.0}, {'name': 'Dinner', 'items': [{'name': 'salmon', 'qty': '150', 'unit': 'g', 'kcal': '300'}, {'name': 'salad', 'qty': '1', 'unit': 'serving', 'kcal': '100'}], 'total_kcal': 400.0}]\nmeal_list [{'name': 'Breakfast', 'items': [{'name': 'oats', 'qty': '1', 'unit': 'cup', 'kcal': '300'}, {'name': 'banana', 'qty': '1', 'unit': 'item', 'kcal': '100'}], 'total_kcal': 400.0}, {'name': 'Lunch', 'items': [{'name': 'rice', 'qty': '200', 'unit': 'g', 'kcal': '260'}, {'name': 'chicken', 'qty': '150', 'unit': 'g', 'kcal': '250'}], 'total_kcal': 510.0}, {'name': 'Snacks', 'items': [{'name': 'almonds', 'qty': '30', 'unit': 'g', 'kcal': '170'}], 'total_kcal': 170.0}, {'name': 'Dinner', 'items': [{'name': 'salmon', 'qty': '150', 'unit': 'g', 'kcal': '300'}, {'name': 'salad', 'qty': '1', 'unit': 'serving', 'kcal': '100'}], 'total_kcal': 400.0}]\nEstimated daily calories from typical meals: 1480.0 kcal\nComputed maintenance estimate (assumed age=30, activity factor=1.4): 2019 kcal\nUser calorie target set to: (1719, 2319)\n","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"\nWhat would you like me to do now? (e.g., 'Make me a workout plan and remind me to drink water', or 'evaluate my meals', or 'diet chart'):  Diet chart\n"},{"name":"stderr","text":"2025-12-01 19:17:41,786 INFO LLM call 663feeb5 started (len(prompt)=290)\n2025-12-01 19:17:41,873 INFO AFC is enabled with max remote calls: 10.\n2025-12-01 19:17:42,476 INFO HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 19:17:42,478 INFO LLM call 663feeb5 finished in 0.692s\n2025-12-01 19:17:42,479 INFO LLM decided tools: ['create_diet_chart']\n2025-12-01 19:17:42,480 INFO LLM call d36e4f94 started (len(prompt)=1107)\n2025-12-01 19:17:42,564 INFO AFC is enabled with max remote calls: 10.\n","output_type":"stream"},{"name":"stdout","text":"Gemini Call\nGemini Call\n","output_type":"stream"},{"name":"stderr","text":"2025-12-01 19:18:17,179 INFO HTTP Request: POST https://generativelanguage.googleapis.com/v1beta/models/gemini-2.5-flash:generateContent \"HTTP/1.1 200 OK\"\n2025-12-01 19:18:17,183 INFO LLM call d36e4f94 finished in 34.703s\n2025-12-01 19:18:17,185 INFO METRICS: {'llm_calls': 3, 'errors': 0, 'total_llm_time_s': 44.89281487464905, 'sequential_flows': 0, 'parallel_flows': 0, 'loop_iterations': 0}\n","output_type":"stream"},{"name":"stdout","text":"Gemini Call\nGemini Call\n=== Results ===\n{\n  \"created_meals\": [\n    {\n      \"name\": null,\n      \"items\": [\n        {\n          \"name\": \"oatmeal\",\n          \"qty\": 1,\n          \"unit\": \"cup (dry)\",\n          \"kcal\": 300\n        },\n        {\n          \"name\": \"berries\",\n          \"qty\": 0.5,\n          \"unit\": \"cup\",\n          \"kcal\": 40\n        },\n        {\n          \"name\": \"protein powder\",\n          \"qty\": 1,\n          \"unit\": \"scoop\",\n          \"kcal\": 120\n        },\n        {\n          \"name\": \"brown rice\",\n          \"qty\": 150,\n          \"unit\": \"g (cooked)\",\n          \"kcal\": 170\n        },\n        {\n          \"name\": \"chicken breast\",\n          \"qty\": 150,\n          \"unit\": \"g (cooked)\",\n          \"kcal\": 250\n        },\n        {\n          \"name\": \"mixed vegetables\",\n          \"qty\": 1,\n          \"unit\": \"cup\",\n          \"kcal\": 80\n        },\n        {\n          \"name\": \"olive oil\",\n          \"qty\": 1,\n          \"unit\": \"tbsp\",\n          \"kcal\": 120\n        },\n        {\n          \"name\": \"apple\",\n          \"qty\": 1,\n          \"unit\": \"medium\",\n          \"kcal\": 95\n        },\n        {\n          \"name\": \"almonds\",\n          \"qty\": 30,\n          \"unit\": \"g\",\n          \"kcal\": 170\n        },\n        {\n          \"name\": \"salmon fillet\",\n          \"qty\": 150,\n          \"unit\": \"g (cooked)\",\n          \"kcal\": 300\n        },\n        {\n          \"name\": \"sweet potato\",\n          \"qty\": 1,\n          \"unit\": \"medium\",\n          \"kcal\": 130\n        },\n        {\n          \"name\": \"broccoli\",\n          \"qty\": 1,\n          \"unit\": \"cup\",\n          \"kcal\": 50\n        },\n        {\n          \"name\": \"olive oil\",\n          \"qty\": 1,\n          \"unit\": \"tbsp\",\n          \"kcal\": 120\n        }\n      ],\n      \"total_kcal\": 1945.0\n    }\n  ]\n}\n","output_type":"stream"}],"execution_count":623}]}